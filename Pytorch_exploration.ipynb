{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch exploration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mQnr9powCcP"
      },
      "source": [
        "# Pytorch learning \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKYwYElowIHy"
      },
      "source": [
        "In this notebook I cover a set of tutorials about PyTorch. First, I start with this notebook https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/ and cover a series of 5 of them. When I switch to a new notebook, I explicitely mention it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT0OzClIyBBw"
      },
      "source": [
        "## Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcvBtUI_yNbv"
      },
      "source": [
        "Let's create a tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVbUJCZjwGMa"
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DPmkIMjx0Ks",
        "outputId": "1ff68ca0-5886-4a50-9881-383d5b42bfe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "tsr = torch.Tensor(3, 5)\n",
        "tsr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.0387e-35, 0.0000e+00, 3.7835e-44, 0.0000e+00,        nan],\n",
              "        [0.0000e+00, 1.3733e-14, 6.4069e+02, 4.3066e+21, 1.1824e+22],\n",
              "        [4.3066e+21, 6.3828e+28, 3.8016e-39, 0.0000e+00, 1.4394e-35]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6LwI3kOyR1G"
      },
      "source": [
        "To create a graph corresponding to a tensor, we need to pass a parameter. They are 2 ways to do it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y8fZ9gIya0T"
      },
      "source": [
        "# Way number 1\n",
        "tsr.requires_grad = True\n",
        "# Way number 2\n",
        "t1 = torch.randn((3, 3), requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBRgjCGrzBih"
      },
      "source": [
        "Let's implement a simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Iro0s9zAQO",
        "outputId": "5e5e9967-6a48-406a-c6e4-57224fc863ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "a = torch.randn((3, 3), requires_grad=True)\n",
        "\n",
        "w1 = torch.randn((3, 3), requires_grad=True)\n",
        "w2 = torch.randn((3, 3), requires_grad=True)\n",
        "w3 = torch.randn((3, 3), requires_grad=True)\n",
        "w4 = torch.randn((3, 3), requires_grad=True)\n",
        "\n",
        "b = w1 * a\n",
        "c = w2 * a\n",
        "d = w3 * b + w4 * c\n",
        "L = 10 -d\n",
        "print(\"The grad fn for a is \", a.grad_fn)\n",
        "print(\"the grad fn for d is \", d.grad_fn)\n",
        "print(\"the grad fn for b is \", b.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The grad fn for a is  None\n",
            "the grad fn for d is  <AddBackward0 object at 0x7f99a279ff98>\n",
            "the grad fn for b is  <MulBackward0 object at 0x7f99a279ff28>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCJbx9cX0Pmw"
      },
      "source": [
        "All mathematical operations are implemented by the *torch.nn.Autograd.Function* class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exRvfZHYMdUH"
      },
      "source": [
        "The backward propagation can be called only on a scalar value. If I call it on a tensor, I get an error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIpkvf860OmN",
        "outputId": "0cb4d96c-ba61-476a-8a84-a73cf63ff800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "L.backward()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f2b450ea7f13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE1p0cbVM07e"
      },
      "source": [
        "\n",
        "it can be overcome using an array of scalar values with the size of the Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umjtT2EVMzxF"
      },
      "source": [
        "L.backward(torch.ones(L.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4_LvURQNdaB"
      },
      "source": [
        "## Difference to tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_XgqvukNgqP"
      },
      "source": [
        "Graphs are created dynamically in PyTorch, so until the function *forward* is called, no graph is created"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfF8-8ysONN9"
      },
      "source": [
        "After each run of the forward function all non-leaf node buffers are computed. After running the backward, they are automatically destroyed, while leaf nodes are updated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kG3yF8QMptF",
        "outputId": "69b0234c-3551-452a-b94e-1b9a4c11f872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "L.backward(torch.ones(L.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-17b49626d50c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5EbLCa6Oqej"
      },
      "source": [
        "It allows networks to be created on the fly, since graph is created after explicitely calling forward function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHM1G6RXPg8A"
      },
      "source": [
        "## Useful operators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fYGYbfwPn-4"
      },
      "source": [
        "*requires_grad* - gradient isn't needed for freezed layers.\n",
        "\n",
        "*no_grad* when doing inference, there's no need to compute the memory and, therefore, memory can be saved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTA-Nq1qIE2k"
      },
      "source": [
        "# Building Your First Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr_LTUrOILjl"
      },
      "source": [
        "In this part I cover the topics from https://blog.paperspace.com/pytorch-101-building-neural-networks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiONZ7AYJBSu"
      },
      "source": [
        "*nn.Module* means an arbitraty function **f** in pytorch. To create a network 2 function need to be overwritten: *\\__init__* and *forward*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj22lkhfJm05"
      },
      "source": [
        "*nn.Sequential* is another class which is widely used in pytorch. It accepts a set of *nn.Module* objects and returns an *nn.Sequentil* object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6cjWaChJ8BL"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIrLrrI4JxDk",
        "outputId": "52fbf5db-781e-49ce-93c1-aacab4d2dccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "combinedNetwork = nn.Sequential(nn.Linear(5, 10), nn.Linear(10, 20))\n",
        "type(combinedNetwork)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.modules.container.Sequential"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yJAWMLGL1FJ",
        "outputId": "a4904e73-5e30-4daa-de22-cae75f0b25a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "network = combinedNetwork(torch.from_numpy(np.random.randn(5)).float())\n",
        "type(network)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnLnBqndIf2o"
      },
      "source": [
        "the benefit of *DataLoader* is that it automatically converts the output to Tensor type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfniNUtdDV2W"
      },
      "source": [
        "## Going deep with neural nets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0qjvvdLDYeN"
      },
      "source": [
        "In this part, I cover https://blog.paperspace.com/pytorch-101-advanced/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAY6FrycEaoS"
      },
      "source": [
        "The main difference between *nn.Module* and *nn.Functional* is the following. The former has a state(since each layer need to keep the weights and gradients). The functions from *nn.Functional* are used for stateful-ness operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDrD9mPoFbTa"
      },
      "source": [
        "Another interesting class is *nn.Parameter* To demonstate it, I define a simple net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ntHuafrFlUi",
        "outputId": "d487501f-1b7a-447c-908a-75f18ed50f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "class Mynet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(10, 5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.linear(x)\n",
        "    return output\n",
        "\n",
        "mynet = Mynet()\n",
        "list(mynet.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.0605, -0.1577, -0.2564,  0.2327, -0.0998,  0.3030, -0.1706, -0.0659,\n",
              "          -0.0222, -0.1855],\n",
              "         [-0.1012,  0.1191, -0.1285, -0.0612, -0.2749,  0.0721, -0.1269, -0.1609,\n",
              "          -0.2924,  0.0676],\n",
              "         [ 0.2205, -0.0171,  0.2662, -0.3061, -0.1241,  0.3135, -0.1262, -0.0601,\n",
              "          -0.0219,  0.2227],\n",
              "         [-0.2299, -0.0571, -0.2580, -0.1033,  0.2799, -0.1813, -0.0012,  0.3117,\n",
              "          -0.2663, -0.3112],\n",
              "         [-0.2855, -0.0405,  0.0629, -0.1601,  0.3151,  0.1530, -0.0834,  0.1996,\n",
              "           0.0059, -0.0091]], requires_grad=True), Parameter containing:\n",
              " tensor([ 0.2642, -0.2559, -0.0846, -0.1772,  0.2134], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsnmYj81GP7T"
      },
      "source": [
        "As you see above, the parameters from the linear level are automatically recognized by the net as its parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igJfr_2YGtUQ"
      },
      "source": [
        "Everything that is inside \\__init__ function is added as parameters. Exeption is only for Tensor class, such as *tensor.ones* and *tensor.zeros*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B36iZ1LHRCM"
      },
      "source": [
        "To make it show up, an *nn.Parameter* class must be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNgbML5EHYyE",
        "outputId": "e71a0837-97fd-4f6c-dee7-27fbe31ae4bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "class Mynet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(10, 5)\n",
        "    self.inner = nn.Parameter(torch.zeros(4))\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.linear(x)\n",
        "    return output\n",
        "\n",
        "mynet = Mynet()\n",
        "list(mynet.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0., 0., 0., 0.], requires_grad=True), Parameter containing:\n",
              " tensor([[-0.2888, -0.0802,  0.0872, -0.1590, -0.0287, -0.0796,  0.1052, -0.0085,\n",
              "          -0.2639,  0.2807],\n",
              "         [-0.1082,  0.0433, -0.2152, -0.0853,  0.2812, -0.0872,  0.2499, -0.3032,\n",
              "           0.2299, -0.2259],\n",
              "         [ 0.1409,  0.1870, -0.3132, -0.2750,  0.0386,  0.0013, -0.1540,  0.1911,\n",
              "          -0.1353, -0.0429],\n",
              "         [ 0.1782, -0.0319, -0.0177, -0.1158,  0.1186, -0.1488,  0.1651, -0.0716,\n",
              "          -0.2456, -0.1220],\n",
              "         [ 0.0268,  0.1888, -0.2030, -0.1096,  0.3083, -0.1071, -0.1529,  0.1707,\n",
              "           0.0433,  0.2223]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.2261,  0.1739,  0.1476, -0.0485,  0.1648], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNgAtngxHj5x"
      },
      "source": [
        "When a stack of layers is defined, they are not recognized by a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MbpDuryHiZx",
        "outputId": "7efb8667-2cb8-4e21-d9e4-c07689136c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "layers_list = [nn.Linear(10, 5), nn.Linear(5, 15), nn.Linear(15, 20)]\n",
        "\n",
        "class Mynet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = layers_list\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.layers(x)\n",
        "    return output\n",
        "\n",
        "mynet = Mynet()\n",
        "list(mynet.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_PbYWr5H8T7"
      },
      "source": [
        "To change it, *nn.ModuleList* or *nn.ParameterList* must be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhNT-E5GIDYr",
        "outputId": "07b2b42d-930c-4a2f-9e45-ddd3a707eb67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "layers_list = [nn.Linear(10, 5), nn.Linear(5, 15), nn.Linear(15, 20)]\n",
        "parameter_list = [nn.Parameter(torch.ones(10))]\n",
        "\n",
        "class Mynet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList(layers_list)\n",
        "    self.params = nn.ParameterList(parameter_list)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.layers(x)\n",
        "    return output\n",
        "\n",
        "mynet = Mynet()\n",
        "list(mynet.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.2256,  0.1057, -0.0938,  0.1719, -0.0162, -0.0553, -0.1997,  0.2098,\n",
              "          -0.2369,  0.1588],\n",
              "         [-0.0916,  0.1186,  0.2654, -0.0181, -0.1121,  0.1290, -0.0324, -0.0633,\n",
              "          -0.0599,  0.2931],\n",
              "         [ 0.0052, -0.2441, -0.0056, -0.1030,  0.2593, -0.0070,  0.1628, -0.3102,\n",
              "          -0.2755,  0.2872],\n",
              "         [ 0.2851,  0.2772, -0.1978, -0.2040,  0.1724,  0.0808,  0.1916, -0.2662,\n",
              "           0.1573,  0.2082],\n",
              "         [ 0.0880,  0.0807, -0.1373, -0.2930, -0.0022,  0.1389,  0.0883, -0.1949,\n",
              "           0.3004,  0.1947]], requires_grad=True), Parameter containing:\n",
              " tensor([0.1116, 0.1571, 0.2895, 0.0630, 0.1353], requires_grad=True), Parameter containing:\n",
              " tensor([[ 0.3368, -0.2188,  0.0900, -0.1622, -0.1693],\n",
              "         [-0.1741, -0.3960, -0.3861,  0.3227, -0.0122],\n",
              "         [ 0.2166,  0.3882, -0.3045, -0.3232,  0.2660],\n",
              "         [ 0.4345,  0.2395,  0.0025,  0.3183,  0.4440],\n",
              "         [ 0.1576, -0.1098,  0.3615,  0.3684,  0.0667],\n",
              "         [ 0.1805, -0.4125, -0.2852,  0.1574,  0.4193],\n",
              "         [ 0.1439, -0.4363,  0.0747,  0.1206, -0.4209],\n",
              "         [ 0.4312, -0.1640,  0.0237, -0.1890, -0.0633],\n",
              "         [ 0.1736, -0.3438, -0.3320, -0.3677,  0.0464],\n",
              "         [-0.4143,  0.2731, -0.1836,  0.1028,  0.1179],\n",
              "         [-0.1034, -0.0038, -0.4370, -0.0337,  0.2826],\n",
              "         [-0.2650, -0.0667,  0.1752,  0.3975, -0.1699],\n",
              "         [ 0.4018,  0.2719, -0.2409,  0.0606, -0.3086],\n",
              "         [ 0.4069,  0.1013,  0.1486, -0.1060,  0.1671],\n",
              "         [ 0.1837, -0.3556, -0.0808,  0.0570, -0.1277]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.3027, -0.2562, -0.3638, -0.1744, -0.2997,  0.3479,  0.2943, -0.1042,\n",
              "          0.1260,  0.0081,  0.0442, -0.1838,  0.1411, -0.4442,  0.4048],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([[-0.1640,  0.0423, -0.0473, -0.0694, -0.0432, -0.0385, -0.2344,  0.1377,\n",
              "           0.0828, -0.0903,  0.1241, -0.1165, -0.0967,  0.1671, -0.0872],\n",
              "         [ 0.1213, -0.0528, -0.0410, -0.1774,  0.1809,  0.2390, -0.1455, -0.0032,\n",
              "          -0.0172,  0.0646,  0.1527, -0.2521, -0.0760, -0.0666, -0.2038],\n",
              "         [-0.0883, -0.1374,  0.2283, -0.1496,  0.2313, -0.2152,  0.1946, -0.0981,\n",
              "          -0.2326, -0.0269, -0.1347, -0.2574, -0.1792,  0.2093,  0.0276],\n",
              "         [-0.1482, -0.1808,  0.0847, -0.2156, -0.0623, -0.2569,  0.1113,  0.0890,\n",
              "          -0.1327, -0.0068, -0.2432,  0.1249, -0.0097, -0.1980,  0.0041],\n",
              "         [ 0.1957,  0.1942, -0.2151, -0.1018, -0.2225, -0.0260, -0.0547,  0.0020,\n",
              "          -0.2483,  0.1280, -0.0200, -0.2047, -0.1522,  0.0649, -0.1295],\n",
              "         [-0.1432, -0.0972,  0.1809,  0.1930, -0.1507, -0.1244, -0.1226, -0.2374,\n",
              "          -0.1770,  0.2257,  0.1787,  0.0706,  0.1854, -0.1364,  0.1055],\n",
              "         [ 0.1745,  0.1841,  0.0594,  0.1937, -0.1157,  0.0926,  0.0457, -0.1280,\n",
              "           0.1285,  0.0336,  0.1766,  0.1741,  0.0345,  0.1731,  0.1996],\n",
              "         [-0.1523, -0.0788,  0.0120, -0.0630,  0.0908,  0.1410,  0.1070, -0.1478,\n",
              "           0.2402, -0.1469, -0.1378, -0.0240, -0.1803,  0.2215, -0.1256],\n",
              "         [ 0.0584,  0.1064, -0.0981, -0.2482, -0.1255, -0.1343,  0.2084, -0.2242,\n",
              "           0.0340,  0.2333, -0.0099, -0.0481, -0.0560,  0.1890,  0.2488],\n",
              "         [-0.2483,  0.0815, -0.0214,  0.2239, -0.2267,  0.2465, -0.2268, -0.2357,\n",
              "           0.0964, -0.0334, -0.1538, -0.1821, -0.2253,  0.1425, -0.1499],\n",
              "         [ 0.1353, -0.1764, -0.2458, -0.0937,  0.1893, -0.1826,  0.0350,  0.0200,\n",
              "          -0.0516,  0.0183, -0.2426, -0.0412, -0.2495, -0.0397, -0.2217],\n",
              "         [ 0.0997, -0.0908, -0.0971,  0.1770, -0.0431, -0.2230,  0.0981,  0.2455,\n",
              "           0.0138,  0.1171, -0.1692, -0.2019,  0.0663, -0.0848, -0.0508],\n",
              "         [ 0.0650, -0.1942, -0.2419, -0.1711,  0.0542,  0.1506,  0.1409, -0.0594,\n",
              "          -0.0292,  0.2540,  0.0465, -0.1399,  0.0093, -0.2219,  0.1608],\n",
              "         [-0.1970, -0.1855,  0.1424,  0.0016, -0.0143,  0.1134, -0.0692, -0.0725,\n",
              "          -0.1857, -0.0370,  0.1195, -0.0444,  0.2166, -0.0083, -0.1325],\n",
              "         [-0.2525, -0.1210,  0.0969, -0.0391,  0.1857,  0.1796,  0.0796, -0.1614,\n",
              "           0.1030, -0.2029, -0.1953,  0.1533,  0.2082,  0.0916, -0.1523],\n",
              "         [ 0.0886, -0.2223,  0.1237, -0.0327,  0.0363, -0.2384, -0.0719,  0.2218,\n",
              "           0.2264,  0.0380, -0.1740, -0.1006,  0.1986, -0.1901,  0.0454],\n",
              "         [-0.1178, -0.1726, -0.1820, -0.0266, -0.2120,  0.1079,  0.0196, -0.1554,\n",
              "          -0.1220, -0.2419,  0.0662, -0.1337, -0.1285, -0.1945,  0.0627],\n",
              "         [ 0.1682,  0.1134,  0.0554, -0.0661, -0.1063, -0.1324, -0.1019, -0.1655,\n",
              "          -0.1796,  0.1493, -0.1218,  0.0102,  0.1170,  0.0899,  0.2364],\n",
              "         [-0.1309,  0.0974,  0.0990, -0.0620,  0.2141, -0.1194, -0.0447, -0.1125,\n",
              "           0.2144,  0.0684,  0.0377, -0.1328,  0.2105,  0.1067,  0.0293],\n",
              "         [ 0.1335,  0.1583, -0.2244,  0.1117, -0.2441,  0.1186,  0.1202, -0.2426,\n",
              "           0.0819,  0.1554, -0.0362,  0.1203,  0.0100,  0.1841,  0.1355]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-0.1877,  0.0568,  0.0547, -0.0725, -0.2446, -0.0270, -0.0653, -0.2089,\n",
              "         -0.0954, -0.1644, -0.0839,  0.2153,  0.0368,  0.0307,  0.1159,  0.1465,\n",
              "          0.0743,  0.1370, -0.2244, -0.0939], requires_grad=True), Parameter containing:\n",
              " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN0xhOeBlz3d"
      },
      "source": [
        "### Modules\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTnsR7Q_l1s_"
      },
      "source": [
        "We can also access all modules(layers) of the model using *module* function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN1c2v7Gl6Yt",
        "outputId": "f64c7eb5-6464-4a06-ac2d-65d5ede69f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "class Mynet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(10, 5)\n",
        "    self.inner = nn.Parameter(torch.zeros(4))\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.linear(x)\n",
        "    return output\n",
        "\n",
        "mynet = Mynet()\n",
        "\n",
        "list(mynet.modules())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Mynet(\n",
              "   (linear): Linear(in_features=10, out_features=5, bias=True)\n",
              " ), Linear(in_features=10, out_features=5, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5p0x5H090cT"
      },
      "source": [
        "The similar function to *modules* is *named_modules*, it returns an iterator accross layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7sbZUee9zt6",
        "outputId": "5ea8a765-21fa-468d-d8b1-5e81af602a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "for x in mynet.named_modules():\n",
        "  print(x[0], x[1], \"\\n------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Mynet(\n",
            "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
            ") \n",
            "------------------------------------\n",
            "linear Linear(in_features=10, out_features=5, bias=True) \n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUTQ2Rfc_sMJ"
      },
      "source": [
        "### Different Learning Rates for Different Layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPyel8O5AOPj"
      },
      "source": [
        "It's possible to specify different learning rates for different layers of the net by providing different rates for different parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGMRH-Qm_rSk"
      },
      "source": [
        "optimizer = torch.optim.SGD([{\"params\": mynetb.linear.parameters(), 'lr':0.001, \"momentum\":0.9}])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi9C-RihBCsa"
      },
      "source": [
        "### Saving models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt6wM4rQBE_y"
      },
      "source": [
        "It's possible to save models in pytorch using *save* and *load* functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IOdPQ64BRH2",
        "outputId": "b49cfcb5-3165-45cf-c5bc-cbd966653cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "torch.save(mynet, \"mynet.pth\")\n",
        "mynet = torch.load(\"mynet.pth\")\n",
        "print(mynet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mynet(\n",
            "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFzidAdUBu8h"
      },
      "source": [
        "If we specify only the weights, we can save them using *statedict()* function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCtKJI2_BuDz",
        "outputId": "81459f8d-bee9-4fd4-dc61-c5ba8c99c4f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.save(mynet.state_dict(), \"net_state_dict.pth\")\n",
        "mynet.load_state_dict(torch.load(\"net_state_dict.pth\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}